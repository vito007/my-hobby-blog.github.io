
[{"content":"Dlho som sa pohr√°val s my≈°lienkou vytvori≈• si vlastn√Ω blog, ale v≈ædy ma odradili vysok√© mesaƒçn√© poplatky za hosting a komplikovan√© nastavenia. Chcel som nieƒço jednoduch√©, r√Ωchle a hlavne lacn√© - ide√°lne zadarmo alebo za minim√°lne n√°klady. Po dlh≈°om b√°dan√≠ som objavil kombin√°ciu modern√Ωch technol√≥gi√≠, ktor√© mi umo≈ænili vytvori≈• profesion√°lny blog prakticky zadarmo. Tradiƒçn√© hostingov√© slu≈æby ƒçasto stoja 5-15 EUR mesaƒçne, ƒço je pre hobby blog ne√∫merne veƒæa. Rozhodol som sa preto hƒæada≈• alternat√≠vy v cloudov√Ωch slu≈æb√°ch, ktor√© pon√∫kaj√∫ ≈°tedr√© free tier pl√°ny. Moja filozofia bola jasn√°: minim√°lne n√°klady, maxim√°lna funkcionalita a spoƒæahlivos≈•. Po v√Ωskume som sa rozhodol pre kombin√°ciu statick√©ho site gener√°tora a cloudov√©ho hostingu. V√Ωsledok? Modern√Ω, r√Ωchly blog za cenu len jednej dom√©ny roƒçne.\nPou≈æit√© technol√≥gie a n√°klady # Vlastn√° dom√©na: 6,89 EUR/rok Cloudflare (DNS): 0,00 EUR Azure Static Web Apps: 0,00 EUR Hugo (gener√°tor str√°nok): 0,00 EUR GitHub (verzovanie a CI/CD): 0,00 EUR Celkov√© n√°klady: 6,89 EUR roƒçne\nKrok za krokom n√°vod # 1. K√∫pa dom√©ny # Vyberte si registr√°tora dom√©n (ja som pou≈æil [n√°zov registr√°tora]) Zadajte po≈æadovan√© dom√©nov√© meno a dokonƒçite n√°kup Z√≠skate pr√≠stupov√© √∫daje na spr√°vu DNS nastaven√≠ 2. Nastavenie Cloudflare # Zaregistrujte sa na cloudflare.com Pridajte va≈°u dom√©nu do Cloudflare Zme≈àte nameservery u v√°≈°ho registr√°tora na tie, ktor√© poskytne Cloudflare Poƒçkajte na aktiv√°ciu (zvyƒçajne 24 hod√≠n) 3. Vytvorenie GitHub repozit√°ra # Zaregistrujte sa na github.com (ak nem√°te √∫ƒçet) Vytvorte nov√Ω verejn√Ω repozit√°r pre v√°≈° blog Klonujte repozit√°r na v√°≈° poƒç√≠taƒç pomocou git clone [URL] 4. In≈°tal√°cia Hugo # Stiahnite Hugo z gohugo.io Pre Windows: stiahnite ZIP, rozbaƒæte a pridajte do PATH Pre macOS: brew install hugo Pre Linux: sudo apt install hugo alebo stiahnite .deb bal√≠k Overte in≈°tal√°ciu: hugo version 5. Vytvorenie Hugo str√°nky # Prejdite do prieƒçinka s repozit√°rom Vytvorte nov√∫ Hugo str√°nku: hugo new site . Vyberte a nain≈°talujte t√©mu (napr√≠klad): git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke Upravte hugo.toml a nastavte t√©mu: theme = 'ananke' 6. Konfigur√°cia Hugo # Otvorte hugo.toml a nastavte z√°kladn√© parametre: baseURL = \u0026#39;https://vasa-domena.sk\u0026#39; languageCode = \u0026#39;sk\u0026#39; title = \u0026#39;N√°zov v√°≈°ho blogu\u0026#39; theme = \u0026#39;ananke\u0026#39; Prisp√¥sobte menu, footer a ƒèal≈°ie nastavenia podƒæa t√©my 7. Vytvorenie Azure Static Web App # Zaregistrujte sa na portal.azure.com Vytvorte nov√∫ \u0026ldquo;Static Web App\u0026rdquo; Pripojte k v√°≈°mu GitHub repozit√°ru Nastavte build settings: Source: /, App location: /, Output location: /public Azure automaticky vytvor√≠ GitHub Action pre deployment 8. Nastavenie DNS v Cloudflare # V Cloudflare prejdite na DNS nastavenia Vytvorte CNAME z√°znam: www ‚Üí [v√°≈°-azure-url].azurestaticapps.net Vytvorte A z√°znam pre root dom√©nu alebo CNAME alias Nastavte SSL/TLS na \u0026ldquo;Full\u0026rdquo; v Cloudflare 9. P√≠sanie obsahu # Vytvorte nov√Ω pr√≠spevok: hugo new posts/moj-prvy-prispevok.md Editujte s√∫bor v content/posts/ Nastavte draft: false v front matter Pou≈æite Markdown syntax pre form√°tovanie 10. Publikovanie # Otestujte lok√°lne: hugo server -D Commitnite zmeny: git add ., git commit -m \u0026quot;Nov√Ω pr√≠spevok\u0026quot; Pushujte na GitHub: git push origin main Azure automaticky spust√≠ deployment a publikuje zmeny V√Ωhody tohto rie≈°enia # R√Ωchlos≈•: Statick√© s√∫bory sa naƒç√≠taj√∫ bleskovo Bezpeƒçnos≈•: ≈Ωiadna datab√°za = ≈æiadne bezpeƒçnostn√© probl√©my ≈†k√°lovateƒænos≈•: Cloudflare a Azure zvl√°dnu aj vysok√∫ n√°v≈°tevnos≈• N√≠zke n√°klady: Len cena dom√©ny Verzovanie: Cel√° hist√≥ria zmien v Git Automatick√© SSL: Zadarmo HTTPS certifik√°ty Tento setup mi perfektne vyhovuje a m√¥≈æem ho odporuƒçi≈• ka≈æd√©mu, kto hƒæad√° lacn√© a spoƒæahliv√© rie≈°enie pre osobn√Ω blog ƒçi portf√≥lio.\n","date":"8 September 2025","externalUrl":null,"permalink":"/posts/ako_som_si_vytvoril_blog/","section":"Posts","summary":"Kompletn√Ω n√°vod ako si vytvori≈• modern√Ω blog za cenu len jednej dom√©ny roƒçne pomocou Hugo, Azure Static Web Apps a Cloudflare.","title":"Ako som si vytvoril lacn√Ω blog za 6,89 EUR roƒçne","type":"posts"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/tags/azure/","section":"Tags","summary":"","title":"Azure","type":"tags"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/tags/blog/","section":"Tags","summary":"","title":"Blog","type":"tags"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/tags/cloudflare/","section":"Tags","summary":"","title":"Cloudflare","type":"tags"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/tags/hugo/","section":"Tags","summary":"","title":"Hugo","type":"tags"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/","section":"My hobby blog","summary":"","title":"My hobby blog","type":"page"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/tags/n%C3%A1vod/","section":"Tags","summary":"","title":"N√°vod","type":"tags"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/categories/technol%C3%B3gie/","section":"Categories","summary":"","title":"Technol√≥gie","type":"categories"},{"content":"","date":"8 September 2025","externalUrl":null,"permalink":"/categories/web-development/","section":"Categories","summary":"","title":"Web Development","type":"categories"},{"content":"","date":"4 September 2025","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":" Git pre zaƒçiatoƒçn√≠kov - Kompletn√Ω sprievodca # Ahoj! Ako tvoj uƒçiteƒæ ≈•a nauƒç√≠m pracova≈• s Gitom krok za krokom. Git je n√°stroj na verzovanie k√≥du - predstav si ho ako \u0026ldquo;cestovanie v ƒçase\u0026rdquo; pre tvoje projekty.\nKrok 1: ƒåo je Git a preƒço ho potrebuje≈°? # Git ti umo≈æ≈àuje:\nSledova≈• zmeny v k√≥de Vr√°ti≈• sa k star≈°√≠m verzi√°m Spolupracova≈• s ostatn√Ωmi program√°tormi Uchov√°va≈• z√°lohy svojej pr√°ce Predstav si, ≈æe p√≠≈°e≈° esej. S Gitom m√¥≈æe≈° ulo≈æi≈• ka≈æd√∫ verziu, vidie≈• ƒço si zmenil a vr√°ti≈• sa k predch√°dzaj√∫cej verzii, ak nieƒço pokaz√≠≈°.\nKrok 2: In≈°tal√°cia Gitu # Windows: Stiahni Git z git-scm.com\nMac: brew install git alebo stiahni z git-scm.com\nLinux: sudo apt install git\nOveri≈• in≈°tal√°ciu:\ngit --version Krok 3: Prvotn√© nastavenie # git config --global user.name \u0026#34;Tvoje Meno\u0026#34; git config --global user.email \u0026#34;tvoj@email.com\u0026#34; Krok 4: Z√°kladn√© pojmy (mus√≠≈° ich vedie≈•!) # Repository (repo) = prieƒçinok s projektom pod spr√°vou Gitu Commit = \u0026ldquo;sn√≠mka\u0026rdquo; projektu v urƒçitom ƒçase Branch = vetva v√Ωvoja projektu Remote = vzdialen√© √∫lo≈æisko (napr. GitHub) Krok 5: Vytvorenie prv√©ho repozit√°ra # # Vytvor prieƒçinok pre projekt mkdir moj-projekt cd moj-projekt # Inicializuj Git repozit√°r git init Teraz m√°≈° pr√°zdny Git repozit√°r!\nKrok 6: Prv√Ω commit (tvoja prv√° \u0026ldquo;sn√≠mka\u0026rdquo;) # # Vytvor s√∫bor echo \u0026#34;Ahoj svet!\u0026#34; \u0026gt; index.html # Pridaj s√∫bor do \u0026#34;staging area\u0026#34; git add index.html # Urob commit git commit -m \u0026#34;Pridan√Ω prv√Ω s√∫bor\u0026#34; Vysvetlenie:\ngit add = priprav s√∫bor na commit git commit -m \u0026quot;spr√°va\u0026quot; = urob sn√≠mku so spr√°vou Krok 7: Sledovanie stavu # # Zobraz stav repozit√°ra git status # Zobraz hist√≥riu commitov git log # Zobraz zmeny v s√∫boroch git diff Krok 8: Praktick√Ω pr√≠klad - edit√°cia a nov√Ω commit # # Uprav s√∫bor echo \u0026#34;\u0026lt;h1\u0026gt;Moja str√°nka\u0026lt;/h1\u0026gt;\u0026#34; \u0026gt; index.html # Zobraz zmeny git diff # Pridaj zmeny git add index.html # Urob nov√Ω commit git commit -m \u0026#34;Pridan√Ω nadpis\u0026#34; Krok 9: Pr√°ca s vetvami (branches) # # Vytvor nov√∫ vetvu git branch nova-funkcia # Prepni sa na nov√∫ vetvu git checkout nova-funkcia # ALEBO modernej≈°ie: git switch nova-funkcia # Vytvor a prepni sa naraz git checkout -b ina-vetva Preƒço vetvy? Umo≈æ≈àuj√∫ ti pracova≈• na novej funkcii bez ovplyvnenia hlavnej vetvy. Krok 10: Zluƒçovanie vetiev (merge) # # Prepni sa na hlavn√∫ vetvu git switch main # Zl√∫ƒç vetvu git merge nova-funkcia Krok 11: Pripojenie na GitHub/vzdialen√© √∫lo≈æisko # najprv na stranke https://github.com/settings/tokens vygenerujem token ktory pouzijem v prikaze\n# Pripoj vzdialen√© √∫lo≈æisko git remote set-url origin https://TOKEN@github.com/USERNAME/REPO/ # Nahraj k√≥d na GitHub git push -u origin main Krok 12: S≈•ahovanie zmien # # Stiahni zmeny zo vzdialen√©ho √∫lo≈æiska git pull origin main Krok 13: Praktick√© cviƒçenie # Vytvor s√∫bor style.css Pridaj ho do Gitu (git add) Urob commit Vytvor nov√∫ vetvu styling Uprav CSS s√∫bor Commitni zmeny Prepni sa na main Zl√∫ƒç vetvy echo \u0026#34;body { color: blue; }\u0026#34; \u0026gt; style.css git add style.css git commit -m \u0026#34;Pridan√Ω CSS s√∫bor\u0026#34; git checkout -b styling echo \u0026#34;body { color: red; background: yellow; }\u0026#34; \u0026gt; style.css git add style.css git commit -m \u0026#34;Zmenen√© farby\u0026#34; git checkout main git merge styling Krok 14: Rie≈°enie konfliktov # Keƒè dva ƒæudia zmenia ten ist√Ω riadok, Git nevie ktor√∫ verziu pou≈æi≈•:\n# Git oznaƒç√≠ konflikt v s√∫bore takto: \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Tvoja verzia ======= Verzia z inej vetvy \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; branch-name Rie≈°enie: Uprav s√∫bor ruƒçne, zma≈æ znaƒçky \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; a urob commit. Krok 15: U≈æitoƒçn√© pr√≠kazy na z√°ver # # Zobraz v≈°etky vetvy git branch -a # Zma≈æ vetvu git branch -d nazov-vetvy # Vr√°≈• zmeny v s√∫bore git checkout -- nazov-suboru # Zobraz kr√°snu hist√≥riu git log --oneline --graph # Zru≈° posledn√Ω commit (ale ponechaj zmeny) git reset --soft HEAD~1 Tippy pre ka≈ædodenn√© pou≈æ√≠vanie # Commituj ƒçasto - mal√©, logick√© zmeny P√≠≈° jasn√© commit spr√°vy - napr. \u0026ldquo;Opraven√° chyba v prihl√°sen√≠\u0026rdquo; Pou≈æ√≠vaj vetvy - pre ka≈æd√∫ nov√∫ funkciu Testuj pred commitom - uisti sa, ≈æe k√≥d funguje S≈•ahuj zmeny pravidelne - git pull pred zaƒçiatkom pr√°ce Z√°ver # Pam√§taj si: Git je ako z√°chrann√° sie≈• pre tvoj k√≥d. ƒå√≠m viac ho pou≈æ√≠va≈°, t√≠m v√§ƒç≈°iu istotu m√°≈°, ≈æe o svoju pr√°cu nikdy nepr√≠de≈°!\nTento tutori√°l ti poskytol z√°klady pr√°ce s Gitom. Pre pokroƒçilej≈°ie t√©my odpor√∫ƒçam ofici√°lnu dokument√°ciu na git-scm.com. N√°vod vytvoreny pomocou AI\n","date":"4 September 2025","externalUrl":null,"permalink":"/posts/git/zaklady/","section":"Posts","summary":"","title":"Git pre zaƒçiatoƒçn√≠kov - Kompletn√Ω sprievodca","type":"posts"},{"content":"","date":"4 September 2025","externalUrl":null,"permalink":"/tags/programovanie/","section":"Tags","summary":"","title":"Programovanie","type":"tags"},{"content":"","date":"4 September 2025","externalUrl":null,"permalink":"/tags/tutorial/","section":"Tags","summary":"","title":"Tutorial","type":"tags"},{"content":"","date":"4 September 2025","externalUrl":null,"permalink":"/categories/tutori%C3%A1ly/","section":"Categories","summary":"","title":"Tutori√°ly","type":"categories"},{"content":"","date":"4 September 2025","externalUrl":null,"permalink":"/tags/verzovanie/","section":"Tags","summary":"","title":"Verzovanie","type":"tags"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/categories/cloud/","section":"Categories","summary":"","title":"Cloud","type":"categories"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"Devops","type":"tags"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/categories/devops/","section":"Categories","summary":"","title":"DevOps","type":"categories"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":" Preƒço Docker? Docker revolutionalizoval sp√¥sob, ako vyv√≠jame a deployujeme aplik√°cie. Umo≈æ≈àuje zabali≈• aplik√°ciu so v≈°etk√Ωmi z√°vislostmi do prenosn√©ho kontajnera.\n1. √övod do Dockeru # ƒåo je Docker? # Docker je platforma na kontajneriz√°ciu aplik√°ci√≠. Umo≈æ≈àuje zabali≈• aplik√°ciu a v≈°etky jej z√°vislosti do prenosn√©ho kontajnera, ktor√Ω be≈æ√≠ rovnako na ka≈ædom syst√©me.\nZ√°kladn√© pojmy: # Image (obraz) - ≈°abl√≥na na vytvorenie kontajnera Container (kontajner) - be≈æiaca in≈°tancia obrazu Dockerfile - s√∫bor s in≈°trukciami na vytvorenie obrazu Registry - √∫lo≈æisko obrazov (napr. Docker Hub) 2. Spr√°va Images (obrazov) # Teoretick√Ω √∫vod # Image je read-only ≈°abl√≥na, z ktorej sa vytv√°raj√∫ kontajnery. Sklad√° sa z vrstiev (layers), ƒço umo≈æ≈àuje efekt√≠vne zdieƒæanie a caching.\nZ√°kladn√© pr√≠kazy: # # Stiahnutie obrazu docker pull ubuntu:20.04 # Zoznam lok√°lnych obrazov docker images # Vytvorenie obrazu z Dockerfile docker build -t moja-app:1.0 . # Odstr√°nenie obrazu docker rmi ubuntu:20.04 # Zobrazenie hist√≥rie obrazu docker history ubuntu:20.04 Praktick√Ω pr√≠klad - vytvorenie vlastn√©ho obrazu: # # Dockerfile FROM ubuntu:20.04 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y python3 python3-pip COPY app.py /app/ WORKDIR /app CMD [\u0026#34;python3\u0026#34;, \u0026#34;app.py\u0026#34;] # Vytvorenie obrazu docker build -t python-app:1.0 . 3. Spr√°va Containers (kontajnerov) # Pozor: Kontajnery s√∫ doƒçasn√©. Po ich odstr√°nen√≠ sa stratia v≈°etky zmeny, ktor√© neboli ulo≈æen√© do volumes.\nTeoretick√Ω √∫vod # Kontajner je be≈æiaca in≈°tancia obrazu. Je to izolovan√© prostredie s vlastn√Ωm filesyst√©mom, procesmi a sie≈•ov√Ωm rozhran√≠m.\nZ√°kladn√© pr√≠kazy: # # Spustenie kontajnera docker run -d --name web-server nginx # Interakt√≠vne spustenie docker run -it ubuntu:20.04 /bin/bash # Zoznam be≈æiacich kontajnerov docker ps # Zoznam v≈°etk√Ωch kontajnerov docker ps -a # Zastavenie kontajnera docker stop web-server # Spustenie zastaven√©ho kontajnera docker start web-server # Odstr√°nenie kontajnera docker rm web-server # Pripojenie do be≈æiaceho kontajnera docker exec -it web-server /bin/bash Praktick√Ω pr√≠klad: # # Spustenie web servera s portom a n√°zvom docker run -d --name moj-nginx -p 8080:80 nginx # Kontrola logov docker logs moj-nginx # Pripojenie do kontajnera docker exec -it moj-nginx /bin/bash 4. Sie≈•ovanie (Networking) # Teoretick√Ω √∫vod # Docker poskytuje r√¥zne typy siet√≠ pre komunik√°ciu medzi kontajnermi a so vonkaj≈°√≠m svetom:\nTypy siet√≠: # Bridge - Predvolen√° sie≈• pre kontajnery na jednom hoste. Kontajnery m√¥≈æu komunikova≈• medzi sebou a s internetom. Host - Kontajner pou≈æ√≠va priamo sie≈• hosta. Najr√Ωchlej≈°ia mo≈ænos≈•, ale menej izolovan√°. None - Kontajner nem√° pr√≠stup k sieti. Pou≈æ√≠va sa pre ≈°pecifick√© pr√≠pady. Custom - Vlastn√© definovan√© siete s pokroƒçil√Ωmi nastaveniami. Z√°kladn√© pr√≠kazy: # # Zoznam siet√≠ docker network ls # Vytvorenie vlastnej siete docker network create moja-siet # Spustenie kontajnera v konkr√©tnej sieti docker run -d --name app1 --network moja-siet nginx # Pripojenie kontajnera do siete docker network connect moja-siet app1 # Odpojenie kontajnera zo siete docker network disconnect moja-siet app1 # Inform√°cie o sieti docker network inspect moja-siet Praktick√Ω pr√≠klad - komunik√°cia medzi kontajnermi: # # Vytvorenie vlastnej siete docker network create app-network # Spustenie datab√°zy docker run -d --name mysql-db \\ --network app-network \\ -e MYSQL_ROOT_PASSWORD=heslo123 \\ mysql:8.0 # Spustenie web aplik√°cie docker run -d --name web-app \\ --network app-network \\ -p 3000:3000 \\ node:16 # Kontajnery sa m√¥≈æu komunikova≈• cez n√°zvy # web-app m√¥≈æe pristupova≈• k datab√°ze cez \u0026#34;mysql-db:3306\u0026#34; 5. Volumes a Storage # Teoretick√Ω √∫vod # Volumes umo≈æ≈àuj√∫ trval√© ukladanie d√°t mimo kontajnera. Existuj√∫ tri typy:\nTyp Popis Pou≈æitie Named volumes Spravovan√© Dockerom Produkƒçn√© datab√°zy Bind mounts Pripojenie prieƒçinka z hosta V√Ωvoj aplik√°ci√≠ tmpfs mounts Doƒçasn√© √∫lo≈æisko v pam√§ti Citliv√© d√°ta Z√°kladn√© pr√≠kazy: # # Zoznam volumes docker volume ls # Vytvorenie volume docker volume create moje-data # Spustenie kontajnera s volume docker run -d --name db -v moje-data:/var/lib/mysql mysql:8.0 # Bind mount - pripojenie prieƒçinka docker run -d --name web -v /host/path:/container/path nginx # Inform√°cie o volume docker volume inspect moje-data # Odstr√°nenie volume docker volume rm moje-data Praktick√Ω pr√≠klad - trval√© ulo≈æenie datab√°zy: # # Vytvorenie volume pre datab√°zu docker volume create mysql-data # Spustenie MySQL s trval√Ωm √∫lo≈æiskom docker run -d --name mysql-server \\ -e MYSQL_ROOT_PASSWORD=heslo123 \\ -v mysql-data:/var/lib/mysql \\ -p 3306:3306 \\ mysql:8.0 # Aj po odstr√°nen√≠ kontajnera ostan√∫ d√°ta zachovan√© docker rm -f mysql-server docker run -d --name mysql-server2 \\ -e MYSQL_ROOT_PASSWORD=heslo123 \\ -v mysql-data:/var/lib/mysql \\ -p 3306:3306 \\ mysql:8.0 6. Environment Variables a Konfigur√°cia # Teoretick√Ω √∫vod # Environment variables umo≈æ≈àuj√∫ konfigurova≈• aplik√°cie bez zmeny k√≥du. Docker podporuje r√¥zne sp√¥soby ich zad√°vania.\nZ√°kladn√© pr√≠kazy: # # Nastavenie environment variable docker run -e MYSQL_ROOT_PASSWORD=heslo123 mysql:8.0 # Naƒç√≠tanie z .env s√∫boru docker run --env-file .env mysql:8.0 # Zobrazenie environment variables v kontajneri docker exec container_name env Praktick√Ω pr√≠klad s .env s√∫borom: # # .env s√∫bor MYSQL_ROOT_PASSWORD=tajne_heslo MYSQL_DATABASE=moja_databaza MYSQL_USER=user MYSQL_PASSWORD=user_heslo # Spustenie s .env s√∫borom docker run -d --name mysql-configured \\ --env-file .env \\ -v mysql-data:/var/lib/mysql \\ mysql:8.0 7. Docker Compose # Tip: Docker Compose je ide√°lny pre lok√°lny v√Ωvoj a staging prostredia. Pre produkciu zv√°≈æte Kubernetes alebo Docker Swarm.\nTeoretick√Ω √∫vod # Docker Compose umo≈æ≈àuje definova≈• a spravova≈• viac-kontajnerov√© aplik√°cie pomocou YAML s√∫boru. Ide√°lne pre lok√°lny v√Ωvoj a testing.\nZ√°kladn√° syntax docker-compose.yml: # version: \u0026#39;3.8\u0026#39; services: web: build: . ports: - \u0026#34;3000:3000\u0026#34; environment: - NODE_ENV=development volumes: - .:/app depends_on: - database database: image: mysql:8.0 environment: MYSQL_ROOT_PASSWORD: heslo123 MYSQL_DATABASE: myapp volumes: - mysql_data:/var/lib/mysql ports: - \u0026#34;3306:3306\u0026#34; volumes: mysql_data: Z√°kladn√© pr√≠kazy: # # Spustenie v≈°etk√Ωch slu≈æieb docker-compose up -d # Zastavenie v≈°etk√Ωch slu≈æieb docker-compose down # Zobrazenie stavu slu≈æieb docker-compose ps # Zobrazenie logov docker-compose logs # Rebuild a re≈°tart docker-compose up --build # Spustenie pr√≠kazu v slu≈æbe docker-compose exec web /bin/bash Komplexn√Ω praktick√Ω pr√≠klad - Web aplik√°cia s datab√°zou: # Zobrazenie √∫pln√©ho docker-compose.yml # docker-compose.yml version: \u0026#39;3.8\u0026#39; services: # Web aplik√°cia frontend: build: ./frontend ports: - \u0026#34;3000:3000\u0026#34; environment: - REACT_APP_API_URL=http://backend:5000 volumes: - ./frontend:/app - /app/node_modules depends_on: - backend restart: unless-stopped # Backend API backend: build: ./backend ports: - \u0026#34;5000:5000\u0026#34; environment: - DATABASE_URL=mysql://user:heslo@database:3306/myapp - NODE_ENV=development - REDIS_URL=redis://cache:6379 volumes: - ./backend:/app - /app/node_modules depends_on: - database - cache restart: unless-stopped # MySQL datab√°za database: image: mysql:8.0 environment: MYSQL_ROOT_PASSWORD: root_heslo MYSQL_DATABASE: myapp MYSQL_USER: user MYSQL_PASSWORD: heslo volumes: - mysql_data:/var/lib/mysql - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql ports: - \u0026#34;3306:3306\u0026#34; restart: unless-stopped # Redis cache cache: image: redis:alpine command: redis-server --appendonly yes volumes: - redis_data:/data ports: - \u0026#34;6379:6379\u0026#34; restart: unless-stopped # Nginx reverse proxy nginx: image: nginx:alpine ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: - ./nginx/nginx.conf:/etc/nginx/nginx.conf - ./nginx/ssl:/etc/nginx/ssl depends_on: - frontend - backend restart: unless-stopped volumes: mysql_data: redis_data: networks: default: name: myapp-network Spustenie a spr√°va: # # Spustenie celej aplik√°cie docker-compose up -d # Sledovanie logov konkr√©tnej slu≈æby docker-compose logs -f backend # Re≈°tart konkr√©tnej slu≈æby docker-compose restart backend # Scaling slu≈æby docker-compose up --scale backend=3 # Vyƒçistenie v≈°etk√©ho docker-compose down -v --rmi all 8. Bezpeƒçnos≈• a Best Practices # Optimaliz√°cia Dockerfile: # # Dobr√© praktiky FROM node:16-alpine # Vytvorenie non-root usera RUN addgroup -g 1001 -S nodejs \u0026amp;\u0026amp; \\ adduser -S nextjs -u 1001 # Nastavenie working directory WORKDIR /app # Kop√≠rovanie package.json najprv (lep≈°√≠ caching) COPY package*.json ./ RUN npm ci --only=production \u0026amp;\u0026amp; npm cache clean --force # Kop√≠rovanie zdrojov√©ho k√≥du COPY --chown=nextjs:nodejs . . # Nastavenie usera USER nextjs # Definovanie portu EXPOSE 3000 # Health check HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\ CMD curl -f http://localhost:3000/health || exit 1 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] Bezpeƒçnostn√© tipy: # ‚ö†Ô∏è D√îLE≈ΩIT√â: Nikdy neukladajte citliv√© √∫daje priamo do Dockerfile alebo docker-compose.yml! Pou≈æ√≠vajte Docker secrets alebo external configuration.\nDobr√© praktiky:\n‚úÖ Pou≈æ√≠vajte specific image tags namiesto latest ‚úÖ Sp√∫≈°≈•ajte kontajnery ako non-root user ‚úÖ Skenujte images na vulnerabilities ‚úÖ Pou≈æ√≠vajte multi-stage builds ‚ùå Neinkludujte .git, node_modules v build context 9. Monitoring a Debugging # U≈æitoƒçn√© pr√≠kazy na √∫dr≈æbu: # # Vyƒçistenie v≈°etk√Ωch nepou≈æ√≠van√Ωch objektov docker system prune -a # Vyƒçistenie volumes docker volume prune # Zobrazenie vyu≈æitia miesta docker system df # Sledovanie vyu≈æitia zdrojov docker stats # Export/Import kontajnera docker export container_name \u0026gt; backup.tar docker import backup.tar new_image:tag Monitoring a debugging: # # Sledovanie logov v re√°lnom ƒçase docker logs -f --tail 100 container_name # Zobrazenie procesov v kontajneri docker top container_name # In≈°pekcia kontajnera (detailn√© inform√°cie) docker inspect container_name # Kop√≠rovanie s√∫borov do/z kontajnera docker cp file.txt container_name:/path/ docker cp container_name:/path/file.txt ./ # Sledovanie udalost√≠ docker events # Zobrazenie port mappings docker port container_name Docker Compose monitoring: # # Zobrazenie vyu≈æitia zdrojov v≈°etk√Ωch slu≈æieb docker-compose top # Sledovanie logov v≈°etk√Ωch slu≈æieb docker-compose logs -f --tail=100 # Valid√°cia compose s√∫boru docker-compose config # Zobrazenie z√°vislost√≠ medzi slu≈æbami docker-compose ps --services 10. Pokroƒçil√© t√©my # Multi-stage builds # # Build stage FROM node:16-alpine AS builder WORKDIR /app COPY package*.json ./ RUN npm ci COPY . . RUN npm run build # Production stage FROM node:16-alpine AS production WORKDIR /app COPY package*.json ./ RUN npm ci --only=production COPY --from=builder /app/dist ./dist USER node CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] Docker secrets (pre produkciu): # # Vytvorenie secret echo \u0026#34;moje_tajne_heslo\u0026#34; | docker secret create mysql_password - # Pou≈æitie v docker-compose.yml version: \u0026#39;3.8\u0026#39; services: database: image: mysql:8.0 secrets: - mysql_password environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/mysql_password secrets: mysql_password: external: true Z√°ver a ƒèal≈°ie kroky # üéâ Gratulujeme! Teraz pozn√°te z√°klady Dockeru. Docker je mocn√Ω n√°stroj, ktor√Ω zjednodu≈°uje deployment a spr√°vu aplik√°ci√≠.\nKƒæ√∫ƒçov√© koncepty na zapam√§tanie: # Images s√∫ ≈°abl√≥ny, containers s√∫ be≈æiace in≈°tancie Volumes zabezpeƒçuj√∫ trval√© ulo≈æenie d√°t Networks umo≈æ≈àuj√∫ komunik√°ciu medzi kontajnermi Docker Compose zjednodu≈°uje spr√°vu viac-kontajnerov√Ωch aplik√°ci√≠ Environment variables umo≈æ≈àuj√∫ flexibiln√∫ konfigur√°ciu ƒéal≈°ie kroky: # Pre pokroƒçil√Ωch: # Kubernetes orchestr√°cia Docker Swarm clustering CI/CD integr√°cia Container security scanning U≈æitoƒçn√© zdroje: # Docker ofici√°lna dokument√°cia Docker Hub Docker Best Practices üí° Tip pre zaƒçiatoƒçn√≠kov: Zaƒçnite s jednoduch√Ωmi pr√≠kladmi a postupne prid√°vajte komplexnej≈°ie funkcie. Docker v√°m u≈°etr√≠ veƒæa ƒçasu pri v√Ωvoji a deploymente aplik√°ci√≠! N√°vod vytvoreny pomocou AI\n","date":"15 January 2025","externalUrl":null,"permalink":"/posts/docker/docker-zaklady-sprievodca/","section":"Posts","summary":"","title":"Docker - Kompletn√Ω sprievodca pre zaƒçiatoƒçn√≠kov","type":"posts"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/k8s/","section":"Tags","summary":"","title":"K8s","type":"tags"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/kontajneriz%C3%A1cia/","section":"Tags","summary":"","title":"Kontajneriz√°cia","type":"tags"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/kontajnery/","section":"Tags","summary":"","title":"Kontajnery","type":"tags"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":" Preƒço Kubernetes? Kubernetes (k8s) je de facto ≈°tandard pre orchestr√°ciu kontajnerov. Umo≈æ≈àuje automatick√© nasadzovanie, ≈°k√°lovanie a spr√°vu kontajnerizovan√Ωch aplik√°ci√≠ v produkƒçnom prostred√≠.\n1. √övod do Kubernetes # ƒåo je Kubernetes? # Kubernetes je open-source platforma pre orchestr√°ciu kontajnerov. Automatizuje nasadzovanie, ≈°k√°lovanie a spr√°vu kontajnerizovan√Ωch aplik√°ci√≠ naprieƒç klastrom serverov.\nZ√°kladn√© pojmy: # Cluster - skupina uzlov (nodes) spravovan√Ωch Kubernetes Node - fyzick√Ω alebo virtu√°lny server v klastri Pod - najmen≈°ia deployovateƒæn√° jednotka (jeden alebo viac kontajnerov) Service - abstrakcia pre pr√≠stup k aplik√°ci√°m Deployment - deklarat√≠vny sp√¥sob spr√°vy aplik√°ci√≠ Kubernetes vs Docker Compose: # Aspekt Docker Compose Kubernetes ≈†k√°la Jeden host Multi-host cluster ≈†k√°lovanie Manu√°lne Automatick√© Load balancing Z√°kladn√Ω Pokroƒçil√Ω Self-healing Nie √Åno Pou≈æitie Development/Testing Production 2. Kubernetes Architecture # Teoretick√Ω √∫vod # Kubernetes m√° master-slave architekt√∫ru s control plane a worker nodes.\nControl Plane komponenty: # API Server - centr√°lny komunikaƒçn√Ω bod etcd - distribuovan√° datab√°za stavu klastra Controller Manager - spravuje kontrol√©ry Scheduler - rozhoduje o umiestnen√≠ pods Worker Node komponenty: # kubelet - agent komunikuj√∫ci s control plane kube-proxy - sie≈•ov√Ω proxy Container Runtime - Docker/containerd/CRI-O In≈°tal√°cia a setup: # # In≈°tal√°cia kubectl (MacOS) brew install kubectl # Overenie in≈°tal√°cie kubectl version --client # In≈°tal√°cia minikube pre lok√°lny v√Ωvoj brew install minikube # Spustenie lok√°lneho klastra minikube start # Overenie stavu klastra kubectl cluster-info kubectl get nodes Z√°kladn√© kubectl pr√≠kazy: # # Zobrazenie v≈°etk√Ωch zdrojov kubectl get all # Detailn√© inform√°cie o uzloch kubectl describe nodes # Kontexty (prep√≠nanie medzi klastrami) kubectl config get-contexts kubectl config use-context minikube # Pomoc kubectl --help kubectl get --help 3. Pods - Z√°kladn√© jednotky # Teoretick√Ω √∫vod # Pod je najmen≈°ia deployovateƒæn√° jednotka v Kubernetes. Obsahuje jeden alebo viac √∫zko s√∫visiacich kontajnerov, ktor√© zdieƒæaj√∫ sie≈• a storage.\nZ√°kladn√© oper√°cie s Pods: # # Vytvorenie pod z image kubectl run nginx-pod --image=nginx # Zobrazenie pods kubectl get pods # Detailn√© inform√°cie o pod kubectl describe pod nginx-pod # Pr√≠stup do pod kubectl exec -it nginx-pod -- /bin/bash # Zobrazenie logov kubectl logs nginx-pod # Odstr√°nenie pod kubectl delete pod nginx-pod Pod Manifest (YAML): # # pod.yaml apiVersion: v1 kind: Pod metadata: name: web-pod labels: app: web version: v1 spec: containers: - name: nginx image: nginx:1.21 ports: - containerPort: 80 resources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; - name: sidecar image: busybox command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;while true; do echo \u0026#34;$(date): Sidecar running\u0026#34;; sleep 30; done\u0026#39;] # Aplikovanie manifesta kubectl apply -f pod.yaml # Monitorovanie pod kubectl get pod web-pod -w Praktick√Ω pr√≠klad - Multi-container Pod: # # multi-container-pod.yaml apiVersion: v1 kind: Pod metadata: name: app-with-logging spec: containers: # Hlavn√° aplik√°cia - name: app image: nginx:alpine ports: - containerPort: 80 volumeMounts: - name: shared-logs mountPath: /var/log/nginx # Logging sidecar - name: log-processor image: busybox command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;] args: [\u0026#39;tail -f /var/log/nginx/access.log\u0026#39;] volumeMounts: - name: shared-logs mountPath: /var/log/nginx volumes: - name: shared-logs emptyDir: {} 4. Services - Sie≈•ov√° abstrakcia # Teoretick√Ω √∫vod # Services poskytuj√∫ stabiln√Ω endpoint pre pr√≠stup k pods. Rie≈°ia probl√©m dynamick√Ωch IP adries a load balancing.\nTypy Services: # ClusterIP - intern√° komunik√°cia v klastri NodePort - pr√≠stup z vonka cez port na uzle LoadBalancer - extern√Ω load balancer (cloud provider) ExternalName - DNS alias pre extern√© slu≈æby Z√°kladn√© pr√≠kazy: # # Vytvorenie service pre existuj√∫ce pods kubectl expose pod web-pod --type=ClusterIP --port=80 # Zobrazenie services kubectl get services kubectl get svc # Detailn√© inform√°cie kubectl describe service web-pod # Testovanie konektivity kubectl run test-pod --image=busybox -it --rm -- wget -qO- web-pod Service Manifests: # ClusterIP Service: # # service-clusterip.yaml apiVersion: v1 kind: Service metadata: name: web-service spec: selector: app: web ports: - protocol: TCP port: 80 targetPort: 80 type: ClusterIP NodePort Service: # # service-nodeport.yaml apiVersion: v1 kind: Service metadata: name: web-service-external spec: selector: app: web ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30080 type: NodePort LoadBalancer Service (pre cloud): # # service-loadbalancer.yaml apiVersion: v1 kind: Service metadata: name: web-service-lb spec: selector: app: web ports: - protocol: TCP port: 80 targetPort: 80 type: LoadBalancer Praktick√Ω pr√≠klad - Service Discovery: # # Vytvorenie deployment s viacer√Ωmi pods kubectl create deployment web --image=nginx --replicas=3 # Vytvorenie service kubectl expose deployment web --port=80 --type=ClusterIP # Test load balancingu kubectl run test --image=busybox -it --rm -- sh # V kontajneri: # while true; do wget -qO- web; sleep 1; done 5. Deployments - Deklarat√≠vna spr√°va aplik√°ci√≠ # Tip: Deployments s√∫ preferovan√Ω zp≈Øsob nasazovania aplik√°ci√≠ v Kubernetes. Poskytuj√∫ rolling updates, rollbacks a self-healing.\nTeoretick√Ω √∫vod # Deployment je kontrol√©r, ktor√Ω spravuje ReplicaSets a t√Ωm aj Pods. Umo≈æ≈àuje deklarat√≠vne aktualiz√°cie a automatick√© ≈°k√°lovanie.\nZ√°kladn√© oper√°cie: # # Vytvorenie deployment kubectl create deployment nginx-app --image=nginx:1.21 # ≈†k√°lovanie kubectl scale deployment nginx-app --replicas=5 # Rolling update kubectl set image deployment nginx-app nginx=nginx:1.22 # Hist√≥ria zmien kubectl rollout history deployment nginx-app # Rollback na predch√°dzaj√∫cu verziu kubectl rollout undo deployment nginx-app # Status rolling update kubectl rollout status deployment nginx-app Deployment Manifest: # # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: web-deployment labels: app: web spec: replicas: 3 selector: matchLabels: app: web template: metadata: labels: app: web spec: containers: - name: nginx image: nginx:1.21 ports: - containerPort: 80 resources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; livenessProbe: httpGet: path: / port: 80 initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: / port: 80 initialDelaySeconds: 5 periodSeconds: 5 Deployment strat√©gie: # RollingUpdate (default): # spec: strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 25% maxSurge: 25% Recreate: # spec: strategy: type: Recreate Praktick√Ω pr√≠klad - Blue-Green deployment: # # blue-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: app-blue spec: replicas: 3 selector: matchLabels: app: myapp version: blue template: metadata: labels: app: myapp version: blue spec: containers: - name: app image: myapp:v1.0 ports: - containerPort: 8080 --- # service pre blue-green apiVersion: v1 kind: Service metadata: name: app-service spec: selector: app: myapp version: blue # Prepnutie na green pre switch ports: - port: 80 targetPort: 8080 6. ConfigMaps a Secrets - Konfigur√°cia # Teoretick√Ω √∫vod # ConfigMaps a Secrets umo≈æ≈àuj√∫ oddelenie konfigur√°cie od k√≥du aplik√°cie.\nRozdiely: # ConfigMap - nesitliv√© konfiguraƒçn√© d√°ta (plain text) Secret - citliv√© √∫daje (base64 encoded, m√¥≈æe by≈• ≈°ifrovan√©) ConfigMaps: # # Vytvorenie ConfigMap z command line kubectl create configmap app-config \\ --from-literal=DATABASE_URL=postgresql://db:5432/myapp \\ --from-literal=DEBUG=true # Vytvorenie z s√∫boru kubectl create configmap nginx-config --from-file=nginx.conf # Zobrazenie ConfigMap kubectl get configmaps kubectl describe configmap app-config ConfigMap Manifest: # # configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: app-config data: database_url: \u0026#34;postgresql://db:5432/myapp\u0026#34; debug_mode: \u0026#34;true\u0026#34; log_level: \u0026#34;info\u0026#34; # M√¥≈æe obsahova≈• aj cel√© s√∫bory nginx.conf: | server { listen 80; location / { proxy_pass http://backend; } } Secrets: # # Vytvorenie Secret kubectl create secret generic db-credentials \\ --from-literal=username=admin \\ --from-literal=password=supersecret # Vytvorenie TLS secret kubectl create secret tls tls-secret \\ --cert=tls.crt \\ --key=tls.key # Zobrazenie secrets kubectl get secrets Secret Manifest: # # secret.yaml apiVersion: v1 kind: Secret metadata: name: db-credentials type: Opaque data: username: YWRtaW4= # base64 encoded \u0026#39;admin\u0026#39; password: c3VwZXJzZWNyZXQ= # base64 encoded \u0026#39;supersecret\u0026#39; Pou≈æitie v Pod: # Environment Variables: # apiVersion: v1 kind: Pod metadata: name: app-pod spec: containers: - name: app image: myapp:latest env: - name: DATABASE_URL valueFrom: configMapKeyRef: name: app-config key: database_url - name: DB_PASSWORD valueFrom: secretKeyRef: name: db-credentials key: password Volume Mounts: # apiVersion: v1 kind: Pod metadata: name: app-pod spec: containers: - name: app image: myapp:latest volumeMounts: - name: config-volume mountPath: /etc/config - name: secret-volume mountPath: /etc/secrets readOnly: true volumes: - name: config-volume configMap: name: app-config - name: secret-volume secret: secretName: db-credentials 7. Persistent Volumes - Trval√© √∫lo≈æisko # Teoretick√Ω √∫vod # Kubernetes poskytuje abstrakciu pre storage cez Persistent Volumes (PV) a Persistent Volume Claims (PVC).\nKomponenty: # Persistent Volume (PV) - fyzick√© √∫lo≈æisko v klastri Persistent Volume Claim (PVC) - po≈æiadavka na √∫lo≈æisko Storage Class - dynamick√© provisionovanie Storage Classes: # # storageclass.yaml apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: fast-ssd provisioner: kubernetes.io/aws-ebs parameters: type: gp2 fsType: ext4 allowVolumeExpansion: true reclaimPolicy: Delete Persistent Volume: # # persistent-volume.yaml apiVersion: v1 kind: PersistentVolume metadata: name: mysql-pv spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: fast-ssd hostPath: path: /data/mysql Persistent Volume Claim: # # persistent-volume-claim.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mysql-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: fast-ssd Pou≈æitie v Pod/Deployment: # # mysql-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: mysql spec: replicas: 1 selector: matchLabels: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: mysql:8.0 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-secret key: password ports: - containerPort: 3306 volumeMounts: - name: mysql-storage mountPath: /var/lib/mysql volumes: - name: mysql-storage persistentVolumeClaim: claimName: mysql-pvc Praktick√Ω pr√≠klad - StatefulSet pre datab√°zu: # # mysql-statefulset.yaml apiVersion: apps/v1 kind: StatefulSet metadata: name: mysql spec: serviceName: mysql replicas: 1 selector: matchLabels: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: mysql:8.0 env: - name: MYSQL_ROOT_PASSWORD value: \u0026#34;rootpassword\u0026#34; ports: - containerPort: 3306 volumeMounts: - name: mysql-storage mountPath: /var/lib/mysql volumeClaimTemplates: - metadata: name: mysql-storage spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] resources: requests: storage: 10Gi 8. Ingress - HTTP Load Balancing # Teoretick√Ω √∫vod # Ingress poskytuje HTTP/HTTPS routing do slu≈æieb v klastri. Umo≈æ≈àuje definova≈• pravidl√° pre domain-based a path-based routing.\nIngress Controller: # Najprv mus√≠te ma≈• nain≈°talovan√Ω Ingress Controller:\n# Nginx Ingress Controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml # Overenie in≈°tal√°cie kubectl get pods -n ingress-nginx # Pre minikube minikube addons enable ingress Z√°kladn√Ω Ingress: # # basic-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: web-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - host: myapp.local http: paths: - path: / pathType: Prefix backend: service: name: web-service port: number: 80 Pokroƒçil√Ω Ingress s TLS: # # advanced-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: app-ingress annotations: nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;true\u0026#34; nginx.ingress.kubernetes.io/rate-limit: \u0026#34;100\u0026#34; spec: tls: - hosts: - api.myapp.com - www.myapp.com secretName: tls-secret rules: - host: www.myapp.com http: paths: - path: / pathType: Prefix backend: service: name: frontend-service port: number: 80 - host: api.myapp.com http: paths: - path: /api/v1 pathType: Prefix backend: service: name: backend-service port: number: 8080 - path: /api/v2 pathType: Prefix backend: service: name: backend-v2-service port: number: 8080 Testovanie Ingress: # # Pridanie do /etc/hosts echo \u0026#34;$(minikube ip) myapp.local\u0026#34; | sudo tee -a /etc/hosts # Test cez curl curl http://myapp.local # Z√≠skanie Ingress inform√°ci√≠ kubectl get ingress kubectl describe ingress web-ingress 9. Namespaces - Izolacia zdrojov # Teoretick√Ω √∫vod # Namespaces poskytuj√∫ virtu√°lnu izol√°ciu zdrojov v r√°mci jedn√©ho klastra. Umo≈æ≈àuj√∫ organiz√°ciu aplik√°ci√≠ podƒæa prostred√≠ alebo t√≠mov.\nZ√°kladn√© oper√°cie: # # Zobrazenie namespaces kubectl get namespaces # Vytvorenie namespace kubectl create namespace development kubectl create namespace staging kubectl create namespace production # Prepnutie do namespace kubectl config set-context --current --namespace=development # Zobrazenie v≈°etk√Ωch zdrojov v namespace kubectl get all -n development # Odstr√°nenie namespace kubectl delete namespace development Namespace Manifest: # # namespace.yaml apiVersion: v1 kind: Namespace metadata: name: development labels: environment: dev team: frontend Resource Quotas: # # resource-quota.yaml apiVersion: v1 kind: ResourceQuota metadata: name: dev-quota namespace: development spec: hard: requests.cpu: \u0026#34;4\u0026#34; requests.memory: 8Gi limits.cpu: \u0026#34;8\u0026#34; limits.memory: 16Gi persistentvolumeclaims: \u0026#34;10\u0026#34; pods: \u0026#34;20\u0026#34; Network Policies: # # network-policy.yaml apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-all namespace: development spec: podSelector: {} policyTypes: - Ingress - Egress --- apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-frontend-to-backend namespace: development spec: podSelector: matchLabels: app: backend policyTypes: - Ingress ingress: - from: - podSelector: matchLabels: app: frontend ports: - protocol: TCP port: 8080 10. Horizontal Pod Autoscaler (HPA) # Teoretick√Ω √∫vod # HPA automaticky ≈°k√°luje poƒçet pods na z√°klade vyu≈æitia CPU, pam√§te alebo custom metr√≠k.\nPo≈æiadavky: # # In≈°tal√°cia metrics-server kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml # Overenie kubectl get pods -n kube-system | grep metrics-server Vytvorenie HPA: # # HPA na z√°klade CPU kubectl autoscale deployment web-deployment \\ --cpu-percent=50 \\ --min=2 \\ --max=10 # Zobrazenie HPA kubectl get hpa HPA Manifest: # # hpa.yaml apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: web-hpa spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: web-deployment minReplicas: 2 maxReplicas: 20 metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 70 - type: Resource resource: name: memory target: type: Utilization averageUtilization: 80 behavior: scaleDown: stabilizationWindowSeconds: 300 policies: - type: Percent value: 10 periodSeconds: 60 scaleUp: stabilizationWindowSeconds: 0 policies: - type: Percent value: 100 periodSeconds: 15 Testovanie autoscalingu: # # Generovanie load kubectl run load-generator --image=busybox -it --rm -- /bin/sh # V kontajneri: # while true; do wget -q -O- http://web-service; done # Sledovanie HPA kubectl get hpa -w # Sledovanie pods kubectl get pods -w 11. Jobs a CronJobs - D√°vkov√© √∫lohy # Jobs # Jobs zabezpeƒçuj√∫ jednorazov√© spustenie √∫loh s garantovan√Ωm dokonƒçen√≠m.\n# job.yaml apiVersion: batch/v1 kind: Job metadata: name: database-migration spec: completions: 1 parallelism: 1 backoffLimit: 3 template: spec: restartPolicy: Never containers: - name: migration image: migrate/migrate:latest command: [\u0026#34;migrate\u0026#34;] args: [\u0026#34;-path\u0026#34;, \u0026#34;/migrations\u0026#34;, \u0026#34;-database\u0026#34;, \u0026#34;postgres://user:pass@db:5432/dbname?sslmode=disable\u0026#34;, \u0026#34;up\u0026#34;] env: - name: DB_HOST value: \u0026#34;postgresql\u0026#34; CronJobs # CronJobs sp√∫≈°≈•aj√∫ √∫lohy podƒæa cronov√©ho rozvrhu.\n# cronjob.yaml apiVersion: batch/v1 kind: CronJob metadata: name: backup-job spec: schedule: \u0026#34;0 2 * * *\u0026#34; # Ka≈æd√Ω de≈à o 2:00 jobTemplate: spec: template: spec: restartPolicy: OnFailure containers: - name: backup image: postgres:13 command: - /bin/bash - -c args: - pg_dump -h postgresql -U postgres mydb \u0026gt; /backup/backup-$(date +%Y%m%d).sql env: - name: PGPASSWORD valueFrom: secretKeyRef: name: postgres-secret key: password volumeMounts: - name: backup-storage mountPath: /backup volumes: - name: backup-storage persistentVolumeClaim: claimName: backup-pvc 12. Monitoring a Logging # Kubernetes Dashboard: # # In≈°tal√°cia Dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml # Vytvorenie admin usera kubectl create serviceaccount admin-user -n kubernetes-dashboard kubectl create clusterrolebinding admin-user --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:admin-user # Z√≠skanie tokenu kubectl -n kubernetes-dashboard create token admin-user # Proxy pre pr√≠stup kubectl proxy # http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ Prometheus a Grafana stack: # # prometheus-namespace.yaml apiVersion: v1 kind: Namespace metadata: name: monitoring --- # prometheus-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: prometheus namespace: monitoring spec: replicas: 1 selector: matchLabels: app: prometheus template: metadata: labels: app: prometheus spec: containers: - name: prometheus image: prom/prometheus:latest ports: - containerPort: 9090 volumeMounts: - name: prometheus-config mountPath: /etc/prometheus/ - name: prometheus-storage mountPath: /prometheus/ volumes: - name: prometheus-config configMap: name: prometheus-config - name: prometheus-storage emptyDir: {} Centralizovan√© logovanie s EFK: # # elasticsearch.yaml apiVersion: apps/v1 kind: StatefulSet metadata: name: elasticsearch namespace: logging spec: serviceName: elasticsearch replicas: 1 selector: matchLabels: app: elasticsearch template: metadata: labels: app: elasticsearch spec: containers: - name: elasticsearch image: elasticsearch:7.17.9 env: - name: discovery.type value: single-node - name: ES_JAVA_OPTS value: \u0026#34;-Xms512m -Xmx512m\u0026#34; ports: - containerPort: 9200 volumeMounts: - name: elasticsearch-data mountPath: /usr/share/elasticsearch/data volumeClaimTemplates: - metadata: name: elasticsearch-data spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] resources: requests: storage: 10Gi 13. Bezpeƒçnos≈• v Kubernetes # ‚ö†Ô∏è D√îLE≈ΩIT√â: Bezpeƒçnos≈• v Kubernetes je komplexn√° t√©ma. Implementujte viacvrstvov√Ω security model.\nRBAC (Role-Based Access Control): # # rbac.yaml apiVersion: v1 kind: ServiceAccount metadata: name: app-reader namespace: development --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: pod-reader namespace: development rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;, \u0026#34;services\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: development subjects: - kind: ServiceAccount name: app-reader namespace: development roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io Pod Security Standards: # # pod-security.yaml apiVersion: v1 kind: Pod metadata: name: secure-pod spec: securityContext: runAsNonRoot: true runAsUser: 1000 runAsGroup: 3000 fsGroup: 2000 containers: - name: app image: nginx:alpine securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsNonRoot: true runAsUser: 1000 capabilities: drop: - ALL resources: requests: memory: \u0026#34;64Mi\u0026#34; cpu: \u0026#34;250m\u0026#34; limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m### Network Security Policies: ```yaml # network-security.yaml apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: default-deny-ingress namespace: production spec: podSelector: {} policyTypes: - Ingress --- apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-nginx-ingress namespace: production spec: podSelector: matchLabels: app: web policyTypes: - Ingress ingress: - from: - namespaceSelector: matchLabels: name: ingress-nginx ports: - protocol: TCP port: 80 Secrets Management - Sealed Secrets: # # In≈°tal√°cia Sealed Secrets kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.18.0/controller.yaml # In≈°tal√°cia kubeseal CLI brew install kubeseal # Vytvorenie sealed secret echo -n mypassword | kubectl create secret generic mysecret --dry-run=client --from-file=password=/dev/stdin -o yaml | kubeseal -o yaml \u0026gt; mysealedsecret.yaml # Aplikovanie sealed secret kubectl apply -f mysealedsecret.yaml 14. Helm - Package Manager pre Kubernetes # Teoretick√Ω √∫vod # Helm je package manager pre Kubernetes, ktor√Ω umo≈æ≈àuje definova≈•, in≈°talova≈• a upgradova≈• komplexn√© Kubernetes aplik√°cie pomocou Charts.\nIn≈°tal√°cia Helm: # # MacOS brew install helm # Ubuntu/Debian curl https://baltocdn.com/helm/signing.asc | sudo apt-key add - sudo apt-get install apt-transport-https --yes echo \u0026#34;deb https://baltocdn.com/helm/stable/debian/ all main\u0026#34; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list sudo apt-get update sudo apt-get install helm # Overenie in≈°tal√°cie helm version Z√°kladn√© Helm oper√°cie: # # Pridanie Helm repozit√°ra helm repo add bitnami https://charts.bitnami.com/bitnami helm repo add stable https://charts.helm.sh/stable helm repo update # Vyhƒæad√°vanie charts helm search repo nginx helm search hub wordpress # In≈°tal√°cia aplik√°cie helm install my-nginx bitnami/nginx # Zobrazenie nain≈°talovan√Ωch releases helm list # Upgrade aplik√°cie helm upgrade my-nginx bitnami/nginx --set replicaCount=3 # Rollback helm rollback my-nginx 1 # Odinstalovanie helm uninstall my-nginx Vytvorenie vlastn√©ho Chart: # # Vytvorenie nov√©ho chart helm create myapp # ≈†trukt√∫ra chart myapp/ Chart.yaml # Metadata o chart values.yaml # Defaultn√© hodnoty templates/ # Kubernetes manifesty deployment.yaml service.yaml ingress.yaml _helpers.tpl # Template helpers charts/ # Z√°vislosti .helmignore # Ignorovan√© s√∫bory Chart.yaml: # # Chart.yaml apiVersion: v2 name: myapp description: A Helm chart for my application type: application version: 0.1.0 appVersion: \u0026#34;1.0\u0026#34; dependencies: - name: postgresql version: \u0026#34;11.9.13\u0026#34; repository: \u0026#34;https://charts.bitnami.com/bitnami\u0026#34; condition: postgresql.enabled values.yaml: # # values.yaml replicaCount: 2 image: repository: myapp pullPolicy: IfNotPresent tag: \u0026#34;latest\u0026#34; service: type: ClusterIP port: 80 ingress: enabled: true className: \u0026#34;nginx\u0026#34; annotations: nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;true\u0026#34; hosts: - host: myapp.local paths: - path: / pathType: Prefix tls: - secretName: myapp-tls hosts: - myapp.local resources: limits: cpu: 500m memory: 512Mi requests: cpu: 250m memory: 256Mi autoscaling: enabled: true minReplicas: 2 maxReplicas: 10 targetCPUUtilizationPercentage: 80 postgresql: enabled: true auth: postgresPassword: \u0026#34;supersecret\u0026#34; database: \u0026#34;myapp\u0026#34; Template deployment.yaml: # # templates/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: {{ include \u0026#34;myapp.fullname\u0026#34; . }} labels: {{- include \u0026#34;myapp.labels\u0026#34; . | nindent 4 }} spec: {{- if not .Values.autoscaling.enabled }} replicas: {{ .Values.replicaCount }} {{- end }} selector: matchLabels: {{- include \u0026#34;myapp.selectorLabels\u0026#34; . | nindent 6 }} template: metadata: labels: {{- include \u0026#34;myapp.selectorLabels\u0026#34; . | nindent 8 }} spec: containers: - name: {{ .Chart.Name }} image: \u0026#34;{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\u0026#34; imagePullPolicy: {{ .Values.image.pullPolicy }} ports: - name: http containerPort: 8080 protocol: TCP env: - name: DATABASE_URL value: \u0026#34;postgresql://postgres:{{ .Values.postgresql.auth.postgresPassword }}@{{ include \u0026#34;myapp.fullname\u0026#34; . }}-postgresql:5432/{{ .Values.postgresql.auth.database }}\u0026#34; livenessProbe: httpGet: path: /health port: http initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: /ready port: http initialDelaySeconds: 5 periodSeconds: 5 resources: {{- toYaml .Values.resources | nindent 12 }} Testovanie a deploying Chart: # # Valid√°cia chart helm lint myapp/ # Dry-run in≈°tal√°cia helm install myapp-test ./myapp --dry-run --debug # In≈°tal√°cia s custom hodnotami helm install myapp ./myapp \\ --set replicaCount=3 \\ --set image.tag=v1.2.0 \\ --set postgresql.auth.postgresPassword=newpassword # In≈°tal√°cia s values s√∫borom helm install myapp ./myapp -f production-values.yaml # Package chart helm package myapp/ # Push do repozit√°ra (ak m√°te vlastn√Ω) helm repo index --url https://myrepo.com/charts . 15. Kubernetes Operators # Teoretick√Ω √∫vod # Operators s√∫ Kubernetes aplik√°cie, ktor√© pou≈æ√≠vaj√∫ Custom Resources a Controllers na automatiz√°ciu spr√°vy komplexn√Ωch aplik√°ci√≠.\nCustom Resource Definition (CRD): # # mysql-crd.yaml apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: mysqls.database.example.com spec: group: database.example.com versions: - name: v1 served: true storage: true schema: openAPIV3Schema: type: object properties: spec: type: object properties: size: type: integer minimum: 1 maximum: 100 version: type: string enum: [\u0026#34;5.7\u0026#34;, \u0026#34;8.0\u0026#34;] storageSize: type: string pattern: \u0026#39;^[0-9]+Gi$\u0026#39; status: type: object properties: conditions: type: array items: type: object properties: type: type: string status: type: string reason: type: string scope: Namespaced names: plural: mysqls singular: mysql kind: MySQL shortNames: - mysql Custom Resource: # # mysql-instance.yaml apiVersion: database.example.com/v1 kind: MySQL metadata: name: my-database spec: size: 3 version: \u0026#34;8.0\u0026#34; storageSize: \u0026#34;10Gi\u0026#34; Popul√°rne Operators: # Prometheus Operator: # # In≈°tal√°cia Prometheus Operator helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus prometheus-community/kube-prometheus-stack # Vytvorenie ServiceMonitor kubectl apply -f - \u0026lt;\u0026lt;EOF apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: myapp-metrics spec: selector: matchLabels: app: myapp endpoints: - port: metrics path: /metrics interval: 30s EOF ArgoCD Operator: # # In≈°tal√°cia ArgoCD kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml # Pr√≠stup k ArgoCD kubectl port-forward svc/argocd-server -n argocd 8080:443 # Z√≠skanie admin hesla kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 -d 16. GitOps s ArgoCD # Teoretick√Ω √∫vod # GitOps je metodol√≥gia continuous deployment, kde Git repozit√°r sl√∫≈æi ako single source of truth pre infrastrukt√∫ru a aplik√°cie.\nArgoCD Application: # # application.yaml apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: myapp namespace: argocd spec: project: default source: repoURL: https://github.com/myorg/myapp-k8s targetRevision: main path: manifests destination: server: https://kubernetes.default.svc namespace: production syncPolicy: automated: prune: true selfHeal: true syncOptions: - CreateNamespace=true revisionHistoryLimit: 10 App of Apps pattern: # # apps.yaml apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: apps namespace: argocd spec: project: default source: repoURL: https://github.com/myorg/gitops-apps targetRevision: main path: apps destination: server: https://kubernetes.default.svc namespace: argocd syncPolicy: automated: prune: true selfHeal: true ≈†trukt√∫ra GitOps repozit√°ra: # gitops-repo/ ‚îú‚îÄ‚îÄ apps/ ‚îÇ ‚îú‚îÄ‚îÄ frontend.yaml ‚îÇ ‚îú‚îÄ‚îÄ backend.yaml ‚îÇ ‚îî‚îÄ‚îÄ database.yaml ‚îú‚îÄ‚îÄ infrastructure/ ‚îÇ ‚îú‚îÄ‚îÄ namespaces/ ‚îÇ ‚îú‚îÄ‚îÄ ingress-controllers/ ‚îÇ ‚îî‚îÄ‚îÄ monitoring/ ‚îú‚îÄ‚îÄ environments/ ‚îÇ ‚îú‚îÄ‚îÄ dev/ ‚îÇ ‚îú‚îÄ‚îÄ staging/ ‚îÇ ‚îî‚îÄ‚îÄ production/ ‚îî‚îÄ‚îÄ README.md 17. Service Mesh s Istio # Teoretick√Ω √∫vod # Service Mesh poskytuje komunikaƒçn√∫ infra≈°trukt√∫ru medzi mikroservices s funkciami ako load balancing, service discovery, encryption, observability.\nIn≈°tal√°cia Istio: # # Stiahnutie Istio curl -L https://istio.io/downloadIstio | sh - export PATH=$PWD/istio-1.19.0/bin:$PATH # In≈°tal√°cia do klastra istioctl install --set values.defaultRevision=default # Povolenie sidecar injection kubectl label namespace default istio-injection=enabled Istio Gateway a VirtualService: # # istio-gateway.yaml apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: myapp-gateway spec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - myapp.com - port: number: 443 name: https protocol: HTTPS tls: mode: SIMPLE credentialName: myapp-tls hosts: - myapp.com --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: myapp-vs spec: hosts: - myapp.com gateways: - myapp-gateway http: - match: - uri: prefix: /api/ route: - destination: host: backend-service port: number: 8080 - match: - uri: prefix: / route: - destination: host: frontend-service port: number: 80 Traffic Splitting (Canary Deployment): # # canary-virtualservice.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: backend-canary spec: hosts: - backend-service http: - match: - headers: canary: exact: \u0026#34;true\u0026#34; route: - destination: host: backend-service subset: v2 - route: - destination: host: backend-service subset: v1 weight: 90 - destination: host: backend-service subset: v2 weight: 10 --- apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: backend-destination spec: host: backend-service subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 18. Troubleshooting a Debugging # Z√°kladn√© debugging pr√≠kazy: # # Zobrazenie problematick√Ωch pods kubectl get pods --field-selector=status.phase!=Running # Detailn√© inform√°cie o pod kubectl describe pod \u0026lt;pod-name\u0026gt; # Logs z pod kubectl logs \u0026lt;pod-name\u0026gt; -f kubectl logs \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; # Logs z predch√°dzaj√∫ceho crash kubectl logs \u0026lt;pod-name\u0026gt; --previous # Exec do pod kubectl exec -it \u0026lt;pod-name\u0026gt; -- /bin/bash # Port forwarding pre debugging kubectl port-forward pod/\u0026lt;pod-name\u0026gt; 8080:80 # Debug networking kubectl run debug --image=nicolaka/netshoot -it --rm Problematick√© scen√°re: # Pod stuck v Pending: # # Kontrola resource constraints kubectl describe pod \u0026lt;pod-name\u0026gt; kubectl top nodes kubectl describe nodes # Kontrola taints a tolerations kubectl get nodes -o json | jq \u0026#39;.items[].spec.taints\u0026#39; ImagePullBackOff: # # Kontrola image name a tag kubectl describe pod \u0026lt;pod-name\u0026gt; # Kontrola image pull secrets kubectl get secrets kubectl describe secret \u0026lt;image-pull-secret\u0026gt; # Test pull z node docker pull \u0026lt;image-name\u0026gt; CrashLoopBackOff: # # Kontrola aplikaƒçn√Ωch logov kubectl logs \u0026lt;pod-name\u0026gt; --previous # Kontrola liveness/readiness probes kubectl describe pod \u0026lt;pod-name\u0026gt; # Doƒçasn√© vypnutie probes pre debugging kubectl patch deployment \u0026lt;deployment-name\u0026gt; -p \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;template\u0026#34;:{\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;\u0026lt;container-name\u0026gt;\u0026#34;,\u0026#34;livenessProbe\u0026#34;:null,\u0026#34;readinessProbe\u0026#34;:null}]}}}}\u0026#39; Performance monitoring: # # Resource utilization kubectl top nodes kubectl top pods kubectl top pods -A # Podrobn√© metriky kubectl get --raw /metrics # Events v klastri kubectl get events --sort-by=\u0026#39;.lastTimestamp\u0026#39; kubectl get events -A --sort-by=\u0026#39;.lastTimestamp\u0026#39; 19. Production Best Practices # Resource Management: # # production-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: production-app spec: replicas: 3 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: spec: containers: - name: app image: myapp:v1.2.3 # V≈ædy ≈°pecifick√Ω tag resources: requests: cpu: \u0026#34;500m\u0026#34; memory: \u0026#34;1Gi\u0026#34; limits: cpu: \u0026#34;1000m\u0026#34; memory: \u0026#34;2Gi\u0026#34; livenessProbe: httpGet: path: /health port: 8080 initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 failureThreshold: 3 readinessProbe: httpGet: path: /ready port: 8080 initialDelaySeconds: 5 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 3 env: - name: ENVIRONMENT value: \u0026#34;production\u0026#34; - name: LOG_LEVEL value: \u0026#34;info\u0026#34; Pod Disruption Budgets: # # pdb.yaml apiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: myapp-pdb spec: minAvailable: 2 selector: matchLabels: app: myapp Quality Gates: # # Admission Controllers - OPA Gatekeeper apiVersion: templates.gatekeeper.sh/v1beta1 kind: ConstraintTemplate metadata: name: k8srequiredlabels spec: crd: spec: names: kind: K8sRequiredLabels validation: properties: labels: type: array items: type: string targets: - target: admission.k8s.gatekeeper.sh rego: | package k8srequiredlabels violation[{\u0026#34;msg\u0026#34;: msg}] { required := input.parameters.labels provided := input.review.object.metadata.labels missing := required[_] not provided[missing] msg := sprintf(\u0026#34;Missing required label: %v\u0026#34;, [missing]) } --- apiVersion: constraints.gatekeeper.sh/v1beta1 kind: K8sRequiredLabels metadata: name: must-have-owner spec: match: kinds: - apiGroups: [\u0026#34;apps\u0026#34;] kinds: [\u0026#34;Deployment\u0026#34;] parameters: labels: [\u0026#34;owner\u0026#34;, \u0026#34;environment\u0026#34;] Multi-cluster Strategy: # # cluster-api-cluster.yaml apiVersion: cluster.x-k8s.io/v1beta1 kind: Cluster metadata: name: production-cluster spec: clusterNetwork: services: cidrBlocks: [\u0026#34;10.128.0.0/12\u0026#34;] pods: cidrBlocks: [\u0026#34;192.168.0.0/16\u0026#34;] infrastructureRef: apiVersion: infrastructure.cluster.x-k8s.io/v1beta1 kind: AWSCluster name: production-cluster controlPlaneRef: kind: KubeadmControlPlane apiVersion: controlplane.cluster.x-k8s.io/v1beta1 name: production-cluster-control-plane 20. Z√°ver a ƒèal≈°ie kroky # üéâ Gratulujeme! Pre≈°li sste kompletn√Ωm sprievodcom Kubernetes orchestr√°ciou. Teraz m√°te sol√≠dny z√°klad pre pr√°cu s produkƒçn√Ωmi Kubernetes klastrami.\nKƒæ√∫ƒçov√© koncepty na zapam√§tanie: # Pods s√∫ z√°kladn√© jednotky, Deployments ich spravuj√∫ Services poskytuj√∫ stabiln√Ω pr√≠stup k aplik√°ci√°m ConfigMaps/Secrets oddeƒæuj√∫ konfigur√°ciu od k√≥du Ingress rie≈°i HTTP routing a load balancing Namespaces poskytuj√∫ izol√°ciu a organiz√°ciu HPA zabezpeƒçuje automatick√© ≈°k√°lovanie Helm zjednodu≈°uje deployment komplexn√Ωch aplik√°ci√≠ Odpor√∫ƒçan√Ω learning path: # Zaƒçiatoƒçn√≠ci: # Praktick√© cviƒçenia s minikube Vytvorenie jednoduch√Ωch aplik√°ci√≠ Experimentovanie s kubectl pr√≠kazmi Pochopenie YAML manifestov Pokroƒçil√≠: # Implement√°cia CI/CD pipeline s GitOps Service Mesh (Istio/Linkerd) Custom Controllers a Operators Multi-cluster management Advanced security (Falco, OPA) Produkcia: # Cluster autoscaling Disaster recovery strat√©gie Cost optimization Compliance a governance Performance tuning U≈æitoƒçn√© zdroje: # Kubernetes ofici√°lna dokument√°cia Kubernetes by Example CNCF Landscape Kubernetes Security Best Practices üí° Tip: Kubernetes m√° strm√∫ learning curve, ale systematick√© uƒçenie a praktick√© sk√∫senosti v√°m pom√¥≈æu zvl√°dnu≈• t√∫to mocn√∫ technol√≥giu. Zaƒçnite s jednoduch√Ωmi projektmi a postupne prid√°vajte komplexnej≈°ie funkcie. N√°vod vytvoreny pomocou AI\n","date":"15 January 2025","externalUrl":null,"permalink":"/posts/kubernetes/kubernetes-orchestracia-sprievodca/","section":"Posts","summary":"","title":"Kubernetes - Kompletn√Ω sprievodca orchestr√°ciou kontajnerov","type":"posts"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/orchestr%C3%A1cia/","section":"Tags","summary":"","title":"Orchestr√°cia","type":"tags"},{"content":"Pou≈æit√© technol√≥gie\n√övod # Cloudflare Tunnel je skvel√© rie≈°enie pre bezpeƒçn√Ω pr√≠stup k va≈°emu OpenMediaVault serveru bez potreby vlastnenia verejnej ip adresy. V tomto n√°vode si uk√°≈æeme, ako nastavi≈• Cloudflare Tunnel na OMV6 be≈æiacom na Odroid HC4 pomocou Docker kontajnera.\nPreƒço Docker? # Pou≈æitie Docker kontajnera namiesto priamej in≈°tal√°cie na host syst√©m m√° niekoƒæko v√Ωhod:\nLep≈°ia izol√°cia - kontajner be≈æ√≠ oddelene od host syst√©mu (vy≈°≈°ia bezpeƒçnos≈•) Jednoduch≈°ie aktualiz√°cie - staƒç√≠ stiahnu≈• nov√Ω image R√Ωchly rollback - mo≈ænos≈• r√Ωchleho n√°vratu k predch√°dzaj√∫cej verzii Minim√°lne privil√©gi√° - kontajner be≈æ√≠ s obmedzen√Ωmi pr√°vami Po≈æiadavky # Pred zaƒçat√≠m sa uistite, ≈æe m√°te:\nnain≈°talovan√Ω OMV6 Vlastn√∫ dom√©nu zaregistrovan√∫ na Cloudflare Pr√≠stup k Cloudflare Dashboard SSH pr√≠stup k OMV serveru Krok 1: Pr√≠prava OMV6 # In≈°tal√°cia Docker pluginu # Prihl√°s—Ç–µ sa do OMV Web UI (zvyƒçajne http://IP_ADRESA) Prejdite na System ‚Üí Plugins N√°jdite a nain≈°talujte openmediavault-compose Po in≈°tal√°cii re≈°tartujte OMV: System ‚Üí Reboot Aktiv√°cia Docker slu≈æby # Po re≈°tarte prejdite na Services ‚Üí Compose Aktivujte slu≈æbu ak nie je akt√≠vna Krok 2: Vytvorenie Cloudflare Tunnel # Konfigur√°cia v Cloudflare Dashboard # Prihlaste sa na Cloudflare Dashboard Prejdite na Zero Trust ‚Üí Networks ‚Üí Tunnels Kliknite Create a tunnel Vyberte Cloudflared a zadajte n√°zov (napr. \u0026ldquo;omv-tunnel\u0026rdquo;) D√îLE≈ΩIT√â: Skop√≠rujte tunnel token - zaƒç√≠na s \u0026ldquo;eyJ\u0026hellip;\u0026rdquo; Nastavenie DNS z√°znamu # V tunnel konfigur√°cii pridajte Public Hostname:\nSubdomain: omv (alebo n√°zov podƒæa v√°≈°ho v√Ωberu) Domain: vasa-domena.com Service: HTTP://IP_OMV:80 - IP_OMV = najlepsie ak je to statick√° IP adresa (napriklad 192.168.1.100) Krok 3: Docker Compose konfigur√°cia # V OMV Web UI prejdite na Services ‚Üí Compose ‚Üí Add\nN√°zov: cloudflare-tunnel\nversion: \u0026#39;3.8\u0026#39; services: cloudflared: image: cloudflare/cloudflared:latest container_name: cloudflared-tunnel restart: unless-stopped command: tunnel --no-autoupdate run --token TVOJ_TUNNEL_TOKEN_SEM network_mode: host security_opt: - no-new-privileges:true read_only: true user: \u0026#34;65534:65534\u0026#34; # nobody user environment: - TUNNEL_METRICS=0.0.0.0:8080 healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;wget\u0026#34;, \u0026#34;-q\u0026#34;, \u0026#34;--spider\u0026#34;, \u0026#34;http://localhost:8080/ready\u0026#34;] interval: 10s timeout: 3s retries: 3 # Nezabudnite nahradi≈• TVOJ_TUNNEL_TOKEN_SEM skutoƒçn√Ωm tokenom! Spustenie kontajnera # Kliknite Save Kliknite Up pre spustenie Skontrolujte stav v Containers tabe Krok 4: Verifik√°cia a testovanie # Kontrola stavu kontajnera # # SSH pripojenie k OMV ssh root@IP_OMV # Kontrola be≈æiaceho kontajnera docker ps | grep cloudflared # Kontrola logov docker logs cloudflared-tunnel Test pripojenia # Otvorte prehliadaƒç a prejdite na https://omv.vasa-domena.com. Malo by sa zobrazi≈• OMV login screen.\nPokroƒçil√° konfigur√°cia # Viacero slu≈æieb # Ak chcete vystavi≈• viac slu≈æieb, upravte nastavenia v Cloudflare Dashboard:\nIP adresa hostu na ktorom be≈æia slu≈æby - je to statick√° IP adresa (napriklad 192.168.1.100) , m√¥≈æu to by≈• aj slu≈æby na viacer√Ωch hostoch (r√¥zne ip adresy)\nTunnel ‚Üí Configure ‚Üí Public Hostnames:\nomv.domena.com ‚Üí http://192.168.1.100:80 portainer.domena.com ‚Üí http://192.168.1.100:9443 nextcloud.domena.com ‚Üí http://192.168.1.100:8080 Monitoring # Pre monitoring m√¥≈æete prida≈• do compose s√∫boru:\ntunnel-monitor: image: nicolargo/glances:latest container_name: tunnel-monitor restart: unless-stopped ports: - \u0026#34;61208:61208\u0026#34; volumes: - /var/run/docker.sock:/var/run/docker.sock:ro Rie≈°enie probl√©mov # ƒåast√© probl√©my # Tunnel sa nepripoj√≠:\nSkontrolujte token Verifikujte DNS nastavenia v Cloudflare 403 Error:\nSkontrolujte ƒçi je dom√©na spr√°vne nastaven√° Verifikujte Zero Trust nastavenia Kontajner sa re≈°tartuje:\ndocker logs cloudflared-tunnel --tail 50 U≈æitoƒçn√© pr√≠kazy # # Re≈°tart tunnel docker restart cloudflared-tunnel # Live logy docker logs -f cloudflared-tunnel # Kontrola network docker network ls Bezpeƒçnostn√© odpor√∫ƒçania # Aktivujte Cloudflare Access pre extra zabezpeƒçenie - da sa nastavit multifaktorov√© overovanie, r√¥zne obmedzenia (napr geolokacia, \u0026hellip;) Nastavte firewall pravidl√° - blokujte priamy pr√≠stup na port 80/443 Pravidelne aktualizujte Docker image Monitorujte logy pre podozriv√∫ aktivitu Pou≈æ√≠vajte siln√© hesl√° pre OMV √∫ƒçty Z√°ver # Cloudflare Tunnel poskytuje bezpeƒçn√Ω a spoƒæahliv√Ω sp√¥sob pr√≠stupu k v√°≈°mu OpenMediaVault serveru z ƒæubovoƒæn√©ho miesta na svete bez potreby verejnej ip adresy. Pou≈æitie Docker kontajnera zabezpeƒçuje dodatoƒçn√∫ vrstvu izol√°cie a uƒæahƒçuje √∫dr≈æbu syst√©mu.\nTento setup je ide√°lny pre dom√°cich pou≈æ√≠vateƒæov, ktor√≠ chc√∫ ma≈• vzdialen√Ω pr√≠stup k svojim s√∫borom a slu≈æb√°m.\nN√°vod vytvoreny pomocou AI\n","date":"5 October 2024","externalUrl":null,"permalink":"/posts/cloudflare/hugo-cloudflare-tunnel-post/","section":"Posts","summary":"\u003cp\u003ePou≈æit√© technol√≥gie\u003c/p\u003e\n\u003cimg src=\"https://cf-assets.www.cloudflare.com/dzlvafdwdttg/69wNwfiY5mFmgpd9eQFW6j/d5131c08085a977aa70f19e7aada3fa9/1pixel-down__1_.svg\"  width=\"150\" style=display:inline;padding:10px;\u003e\n\u003cimg src=\"https://www.openmediavault.org/wp-content/uploads/2016/09/header_logo3.png\" width=\"150\" style=display:inline;padding:10px;\u003e\n\u003cimg src=\"https://www.docker.com/app/uploads/2023/08/logo-guide-logos-1.svg\" width=\"150\" style=display:inline;padding:10px;\u003e\n\n\u003ch2 class=\"relative group\"\u003e√övod \n    \u003cdiv id=\"√∫vod\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline\" href=\"#%c3%bavod\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eCloudflare Tunnel je skvel√© rie≈°enie pre bezpeƒçn√Ω pr√≠stup k va≈°emu OpenMediaVault serveru bez potreby vlastnenia verejnej ip adresy. V tomto n√°vode si uk√°≈æeme, ako nastavi≈• Cloudflare Tunnel na OMV6 be≈æiacom na Odroid HC4 pomocou Docker kontajnera.\u003c/p\u003e","title":"Cloudflare Tunnel na OpenMediaVault 6, pr√≠stup bez verejnej IP","type":"posts"},{"content":"","date":"5 October 2024","externalUrl":null,"permalink":"/categories/n%C3%A1vody/","section":"Categories","summary":"","title":"N√°vody","type":"categories"},{"content":"","date":"5 October 2024","externalUrl":null,"permalink":"/tags/odroid/","section":"Tags","summary":"","title":"Odroid","type":"tags"},{"content":"","date":"5 October 2024","externalUrl":null,"permalink":"/tags/omv/","section":"Tags","summary":"","title":"Omv","type":"tags"},{"content":"","date":"5 October 2024","externalUrl":null,"permalink":"/categories/self-hosting/","section":"Categories","summary":"","title":"Self-Hosting","type":"categories"},{"content":"","date":"5 October 2024","externalUrl":null,"permalink":"/tags/self-hosting/","section":"Tags","summary":"","title":"Self-Hosting","type":"tags"},{"content":"","date":"5 October 2024","externalUrl":null,"permalink":"/tags/tunnel/","section":"Tags","summary":"","title":"Tunnel","type":"tags"},{"content":" nauc sa filmovat # ano nie ","externalUrl":null,"permalink":"/videos/naucsa/","section":"Videos","summary":"","title":"","type":"videos"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/videos/","section":"Videos","summary":"","title":"Videos","type":"videos"}]